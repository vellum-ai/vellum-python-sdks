// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`ToolCallingNode > basic > getNodeDisplayFile 1`] = `
"from uuid import UUID

from vellum_ee.workflows.display.editor import NodeDisplayData, NodeDisplayPosition
from vellum_ee.workflows.display.nodes import BaseNodeDisplay
from vellum_ee.workflows.display.nodes.types import PortDisplayOverrides

from ...nodes.tool_calling_node import ToolCallingNode


class ToolCallingNodeDisplay(BaseNodeDisplay[ToolCallingNode]):
    label = "Tool Calling Node"
    node_id = UUID("a72bbfd6-9eb5-48af-9c43-55f1d0a75106")
    attribute_ids_by_name = {
        "ml_model": UUID("75bd1347-dca2-4cba-b0b0-a20a2923ebcc"),
        "blocks": UUID("beec5344-2eff-47d2-b920-b90367370d79"),
        "functions": UUID("7b1ab802-3228-43b3-a493-734c94794710"),
        "prompt_inputs": UUID("38cf126e-a186-4a63-8e30-47c4507413cd"),
        "parameters": UUID("a7f8a575-a7ce-40b9-8bc9-546303f511c1"),
        "max_tool_calls": UUID("723f614a-be30-4f27-90d0-896c740e58d3"),
    }
    port_displays = {
        ToolCallingNode.Ports.default_port: PortDisplayOverrides(
            id=UUID("2544f9e4-d6e6-4475-b6a9-13393115d77c")
        )
    }
    display_data = NodeDisplayData(
        position=NodeDisplayPosition(x=0, y=0), width=None, height=None
    )
"
`;

exports[`ToolCallingNode > basic > getNodeFile 1`] = `
"from .get_current_weather import get_current_weather

from vellum import (
    ChatMessagePromptBlock,
    PlainTextPromptBlock,
    PromptParameters,
    RichTextPromptBlock,
    VariablePromptBlock,
)
from vellum.workflows.nodes.displayable.tool_calling_node import (
    ToolCallingNode as BaseToolCallingNode,
)


class ToolCallingNode(BaseToolCallingNode):
    ml_model = "gpt-4o-mini"
    blocks = [
        ChatMessagePromptBlock(
            chat_role="SYSTEM",
            blocks=[
                RichTextPromptBlock(
                    blocks=[PlainTextPromptBlock(text="""You are a weather expert""")]
                )
            ],
        ),
        ChatMessagePromptBlock(
            chat_role="USER",
            blocks=[
                RichTextPromptBlock(
                    blocks=[VariablePromptBlock(input_variable="question")]
                )
            ],
        ),
    ]
    functions = [get_current_weather]
    prompt_inputs = {
        "question": "What's the weather like in San Francisco?",
    }
    parameters = PromptParameters(
        stop=[],
        temperature=0,
        max_tokens=1000,
        top_p=1,
        top_k=0,
        frequency_penalty=0,
        presence_penalty=0,
        logit_bias={},
        custom_parameters={
            "tool_choice": "AUTO",
        },
    )
    max_tool_calls = 1
"
`;

exports[`ToolCallingNode > composio tool > should generate composio tool 1`] = `
"from vellum.workflows.nodes.displayable.tool_calling_node import (
    ToolCallingNode as BaseToolCallingNode,
)
from vellum.workflows.types.definition import ComposioToolDefinition


class ToolCallingNode(BaseToolCallingNode):
    functions = [
        ComposioToolDefinition(
            toolkit="GITHUB",
            action="GITHUB_CREATE_AN_ISSUE",
            description="Create a new issue in a GitHub repository",
        )
    ]
"
`;

exports[`ToolCallingNode > composio tool > should handle composio tool with integration_name & tool_slug fields 1`] = `
"from vellum.workflows.nodes.displayable.tool_calling_node import (
    ToolCallingNode as BaseToolCallingNode,
)
from vellum.workflows.types.definition import ComposioToolDefinition


class ToolCallingNode(BaseToolCallingNode):
    functions = [
        ComposioToolDefinition(
            toolkit="gmail",
            action="GMAIL_CREATE_EMAIL_DRAFT",
            description="Creates a gmail email draft, supporting to/cc/bcc, subject, plain/html body (ensure \`is html=true\` for html), attachments, and threading.",
        )
    ]
"
`;

exports[`ToolCallingNode > deployment workflow > should generate latest release tag if release_tag is null 1`] = `
"from vellum.workflows.nodes.displayable.tool_calling_node import (
    ToolCallingNode as BaseToolCallingNode,
)
from vellum.workflows.types.definition import DeploymentDefinition


class ToolCallingNode(BaseToolCallingNode):
    functions = [DeploymentDefinition(deployment="deployment_workflow_function_name")]
"
`;

exports[`ToolCallingNode > function ordering > should preserve order: code-exec, workflow 1`] = `
"from .add_numbers import add_numbers
from .subtract.workflow import Subtract

from vellum.workflows.nodes.displayable.tool_calling_node import (
    ToolCallingNode as BaseToolCallingNode,
)


class ToolCallingNode(BaseToolCallingNode):
    functions = [add_numbers, Subtract]
"
`;

exports[`ToolCallingNode > function ordering > should preserve order: workflow, code-exec 1`] = `
"from .add_numbers import add_numbers
from .subtract.workflow import Subtract

from vellum.workflows.nodes.displayable.tool_calling_node import (
    ToolCallingNode as BaseToolCallingNode,
)


class ToolCallingNode(BaseToolCallingNode):
    functions = [Subtract, add_numbers]
"
`;

exports[`ToolCallingNode > inline workflow > should generate inline workflow function name 1`] = `
"from .subtract.workflow import Subtract

from vellum.workflows.nodes.displayable.tool_calling_node import (
    ToolCallingNode as BaseToolCallingNode,
)


class ToolCallingNode(BaseToolCallingNode):
    functions = [Subtract]
"
`;

exports[`ToolCallingNode > input variables > should generate input variables 1`] = `
"from vellum import (
    ChatMessagePromptBlock,
    PlainTextPromptBlock,
    RichTextPromptBlock,
    VariablePromptBlock,
)
from vellum.workflows.nodes.displayable.tool_calling_node import (
    ToolCallingNode as BaseToolCallingNode,
)


class ToolCallingNode(BaseToolCallingNode):
    ml_model = "gpt-4o-mini"
    prompt_inputs = {
        "text": None,
    }
    blocks = [
        ChatMessagePromptBlock(
            chat_role="SYSTEM",
            blocks=[
                RichTextPromptBlock(
                    blocks=[
                        PlainTextPromptBlock(
                            text="""\\
Summarize the following text:

\\
"""
                        ),
                        VariablePromptBlock(input_variable="text"),
                    ]
                )
            ],
        ),
    ]
"
`;
