// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`WorkflowProjectGenerator > Nodes present but not in graph > should still generate a file for the second node 1`] = `
"from vellum.workflows import BaseWorkflow

from .nodes.first_node import FirstNode
from .nodes.second_node import SecondNode


class Workflow(BaseWorkflow):
    graph = FirstNode
    unused_graphs = {SecondNode}
"
`;

exports[`WorkflowProjectGenerator > Nodes present but not in graph > should still generate a file for the second node 2`] = `
"from vellum.workflows.nodes import BaseNode


class SecondNode(BaseNode):
    class Outputs(BaseNode.Outputs):
        output: str
"
`;

exports[`WorkflowProjectGenerator > Nodes present but not in graph > should still generate a file for the second node 3`] = `
"from vellum_ee.workflows.display.nodes import BaseNodeDisplay
from vellum_ee.workflows.display.vellum import NodeDisplayData, NodeDisplayPosition

from ...nodes.second_node import SecondNode


class SecondNodeDisplay(BaseNodeDisplay[SecondNode]):
    node_input_ids_by_name = {}
    display_data = NodeDisplayData(position=NodeDisplayPosition(x=0, y=0), width=None, height=None)
"
`;

exports[`WorkflowProjectGenerator > Nodes present but not in graph > should still generate a file for the second node 4`] = `
"from .first_node import FirstNode
from .second_node import SecondNode

__all__ = ["FirstNode", "SecondNode"]
"
`;

exports[`WorkflowProjectGenerator > Nodes present but not in graph > should still generate a file for the second node 5`] = `
"from .first_node import FirstNodeDisplay
from .second_node import SecondNodeDisplay

__all__ = ["FirstNodeDisplay", "SecondNodeDisplay"]
"
`;

exports[`WorkflowProjectGenerator > Nodes with forward references > should generate a proper Lazy Reference for the first node 1`] = `
"from vellum.workflows.nodes import BaseNode
from vellum.workflows.references import LazyReference


class FirstNode(BaseNode):
    forward = LazyReference("SecondNode.Outputs.output")

    class Outputs(BaseNode.Outputs):
        pass
"
`;

exports[`WorkflowProjectGenerator > code execution node at project level > should not autoformat the script file 1`] = `
"import foo, bar
baz = foo + bar
"
`;

exports[`WorkflowProjectGenerator > combinator normalization > should normalize AND to OR combinators 1`] = `
"from vellum.workflows.nodes.displayable import FinalOutputNode
from vellum.workflows.state import BaseState


class FinalOutput(FinalOutputNode[BaseState, str]):
    class Outputs(FinalOutputNode.Outputs):
        value = 3
"
`;

exports[`WorkflowProjectGenerator > failure cases > should generate code even if a node fails to find invalid ports and target nodes 1`] = `
"from vellum.workflows.nodes.displayable import TemplatingNode
from vellum.workflows.state import BaseState


class BadNode(TemplatingNode[BaseState, str]):
    template = """foo"""
    inputs = {}
"
`;

exports[`WorkflowProjectGenerator > failure cases > should generate code even if a node fails to generate 1`] = `
"from vellum.workflows.nodes.displayable import TemplatingNode
from vellum.workflows.state import BaseState


class BadNode(TemplatingNode[BaseState, str]):
    template = """foo"""
    inputs = {}
"
`;

exports[`WorkflowProjectGenerator > include sandbox > should include a sandbox.py file when passed sandboxInputs 1`] = `
"from vellum import ArrayChatMessageContent, ChatMessage, StringChatMessageContent
from vellum.workflows.sandbox import WorkflowSandboxRunner

from .inputs import Inputs
from .workflow import Workflow

if __name__ != "__main__":
    raise Exception("This file is not meant to be imported")


runner = WorkflowSandboxRunner(
    workflow=Workflow(),
    inputs=[
        Inputs(
            input="foo",
            chat=[
                ChatMessage(role="USER", text="foo"),
            ],
        ),
        Inputs(
            input="bar",
            chat=[
                ChatMessage(role="USER", content=StringChatMessageContent(value="bar")),
            ],
        ),
        Inputs(
            input="hello",
            chat=[
                ChatMessage(
                    role="USER",
                    content=ArrayChatMessageContent(
                        value=[
                            StringChatMessageContent(value="hello"),
                        ]
                    ),
                ),
            ],
        ),
    ],
)

runner.run()
"
`;

exports[`WorkflowProjectGenerator > initialization case > should handle workflow with only ENTRYPOINT and TERMINAL nodes 1`] = `
"from vellum.workflows.nodes.displayable import FinalOutputNode
from vellum.workflows.state import BaseState


class FinalOutput(FinalOutputNode[BaseState, str]):
    class Outputs(FinalOutputNode.Outputs):
        pass
"
`;

exports[`WorkflowProjectGenerator > nodes with output values > should prioritize terminal node data over output values 1`] = `
"from vellum.workflows.nodes.displayable import FinalOutputNode
from vellum.workflows.state import BaseState

from .templating_node import TemplatingNode


class FinalOutput(FinalOutputNode[BaseState, str]):
    class Outputs(FinalOutputNode.Outputs):
        value = TemplatingNode.Outputs.result
"
`;

exports[`WorkflowProjectGenerator > retry node adornment > should correctly generate code for a prompt node with retry adornment 1`] = `
"from vellum import (
    ChatMessagePromptBlock,
    PlainTextPromptBlock,
    PromptParameters,
    RichTextPromptBlock,
    VariablePromptBlock,
)
from vellum.workflows.nodes.core.retry_node.node import RetryNode
from vellum.workflows.nodes.displayable import InlinePromptNode


@RetryNode.wrap(retry_on_error_code=None, max_attempts=5)
class Prompt(InlinePromptNode):
    ml_model = "gpt-4o-mini"
    blocks = [
        ChatMessagePromptBlock(
            chat_role="SYSTEM",
            blocks=[
                RichTextPromptBlock(
                    blocks=[
                        PlainTextPromptBlock(
                            state="ENABLED",
                            cache_config=None,
                            text="""\\
Summarize the following text: hello today is feb 7 bad weather

\\
""",
                        ),
                        VariablePromptBlock(input_variable="text"),
                    ]
                )
            ],
        ),
    ]
    prompt_inputs = {
        "text": None,
    }
    parameters = PromptParameters(
        stop=[],
        temperature=0,
        max_tokens=1000,
        top_p=1,
        top_k=0,
        frequency_penalty=0,
        presence_penalty=0,
        logit_bias={},
        custom_parameters=None,
    )
"
`;

exports[`WorkflowProjectGenerator > runner config with no container image > should handle a runner config with no container image 1`] = `
"from vellum.workflows import BaseWorkflow

from .nodes.templating_node import TemplatingNode


class Workflow(BaseWorkflow):
    graph = TemplatingNode
"
`;

exports[`WorkflowProjectGenerator > should escape special characters > should handle node comments with quotes at the beginning and end 1`] = `
"from vellum.workflows.nodes.displayable import TemplatingNode as BaseTemplatingNode
from vellum.workflows.state import BaseState


class TemplatingNode(BaseTemplatingNode[BaseState, str]):
    """\\"Hello" "World\\""""

    template = """test template"""
    inputs = {}
"
`;

exports[`WorkflowProjectGenerator > should escape special characters > should not escape single quotes in node comments 1`] = `
"from vellum.workflows.nodes.displayable import TemplatingNode as BaseTemplatingNode
from vellum.workflows.state import BaseState


class TemplatingNode(BaseTemplatingNode[BaseState, str]):
    """'Hello' 'World'"""

    template = """test template"""
    inputs = {}
"
`;
